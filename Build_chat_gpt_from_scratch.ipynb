{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVB6vswgcEQcXK/LK9EFOy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anas1IA-art/site/blob/main/Build_chat_gpt_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Chatgpt on based on paper \"Attention is all you need\""
      ],
      "metadata": {
        "id": "E6zSTWmQOSRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPT (Generative Pre-trained Transformer)** is a type of large language model developed by OpenAI that uses transformer architecture to generate human-like text based on input prompts. Its development was based on the paper \"[Improving Language Understanding by Generative Pre-Training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)\" published by OpenAI in 2018.\n",
        "\n",
        "The groundbreaking transformer model, which GPT builds upon, was introduced in the paper \"[Attention is All You Need](https://arxiv.org/abs/1706.03762)\" by Vaswani et al., published in 2017.\n"
      ],
      "metadata": {
        "id": "nxU7f2tdne9u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook contains the notes of **Andrej Karpathy** under the title of [Let's Build GPT: From Scratch, in Code, Spelled Out](https://www.youtube.com/watch?v=kCc8FmEb1nY) on his YouTube channel.\n"
      ],
      "metadata": {
        "id": "eqNHWinWrYZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's  Prepare dataset"
      ],
      "metadata": {
        "id": "Skej0tXgxeuo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial, we utilize the Tiny Shakespeare dataset, a 1.06 MB text file that combines all the works of [William Shakespeare](https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt).\n"
      ],
      "metadata": {
        "id": "mVWXF8ZrxuFO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 419,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "302Kf6qVNy_H",
        "outputId": "be1b6a66-d181-4c03-e29e-c045e09142d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-10 11:10:06--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.5’\n",
            "\n",
            "\rinput.txt.5           0%[                    ]       0  --.-KB/s               \rinput.txt.5         100%[===================>]   1.06M  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-06-10 11:10:06 (127 MB/s) - ‘input.txt.5’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specifying `encoding='utf-8'` ensures that text files are read or written using the UTF-8 encoding, which supports a wide range of characters from various languages. Without this specification, the default system encoding is used, which can lead to inconsistencies and errors, especially with non-ASCII characters.\n",
        "with open('./input.txt','r',encoding  = 'utf-8') as f :\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "D5ET7lxTOngT"
      },
      "execution_count": 420,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD9X2XVbR3da",
        "outputId": "2e4b4dfb-197f-45ee-c17d-01f3cba1ea11"
      },
      "execution_count": 421,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:11])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zhe2tMNyR7ru",
        "outputId": "ffb511b2-8326-48cf-9ba9-5c518b49e963"
      },
      "execution_count": 422,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citiz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "voc_size = len(chars)\n",
        "print(''.join(chars))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYQsvMVeTbK4",
        "outputId": "60cf6fdc-f720-4dfd-be7a-c1008076d431"
      },
      "execution_count": 423,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a mapping from characters to integers using The `enumerate` function in Python adds a counter to an iterable and returns it as an enumerate object, providing both index and value pairs in loops.\n",
        "int_char = {i:ch for i,ch in enumerate(chars , start = 0)}\n",
        "char_int = {ch:i for i,ch in enumerate(chars , start = 0)}\n",
        "int_char[9],char_int['3']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NvehHhxWRMs",
        "outputId": "a663169e-29c9-4b7b-f68d-25d9138bfe1b"
      },
      "execution_count": 424,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('3', 9)"
            ]
          },
          "metadata": {},
          "execution_count": 424
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence  = 'Anas Nouri'\n",
        "# encoder = {} # trasform a sentenece into presentation numeric\n",
        "encoder = lambda s : [char_int[a]for a in s]\n",
        "# encoder(sentence)\n",
        "decoder  =  lambda s : ''.join([int_char[a] for a in s ])\n",
        "decoder(encoder(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vOfYnME5YI5O",
        "outputId": "9d870adb-7d24-481e-c665-e429698c46eb"
      },
      "execution_count": 425,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Anas Nouri'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 425
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder(text[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmCXPk4qlldT",
        "outputId": "af4ce72b-4c4d-4892-db29-c10eb6ea3989"
      },
      "execution_count": 426,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[18, 47, 56, 57, 58, 1, 15, 47, 58, 47]"
            ]
          },
          "metadata": {},
          "execution_count": 426
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
        "import torch"
      ],
      "metadata": {
        "id": "PE2C1w6VdAnJ"
      },
      "execution_count": 427,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = torch.tensor(encoder(text),dtype = torch.long)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-WKGcmvWRO7",
        "outputId": "586a0dcb-eb6f-4ac5-fb26-f74f70c2a110"
      },
      "execution_count": 428,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56,  ..., 45,  8,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 428
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.unsqueeze(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yItrqgPlse6",
        "outputId": "9232bf25-63ee-4dcb-ad7a-b4c24e3a4f13"
      },
      "execution_count": 429,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[18, 47, 56,  ..., 45,  8,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 429
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.squeeze(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3APD5vDl6Ux",
        "outputId": "abad559f-9668-47cd-c614-0d0fc0b7ccab"
      },
      "execution_count": 430,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56,  ..., 45,  8,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 430
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)\n",
        "int(len(dataset)*0.8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxNh-bY1R2wj",
        "outputId": "8eb53d87-0603-4286-823d-ce0e95e65609"
      },
      "execution_count": 431,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "892315"
            ]
          },
          "metadata": {},
          "execution_count": 431
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's now split up the data into train and validation sets\n",
        "n = int(0.8*len(dataset))\n",
        "train_dataset = dataset[:n]\n",
        "validation_dataset = dataset[n:]"
      ],
      "metadata": {
        "id": "12TJPSWumRc-"
      },
      "execution_count": 432,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Block_size = 10\n",
        "train_data = dataset[:Block_size]\n",
        "target_data = dataset[1:Block_size+1]\n",
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u55lQLr3o-o1",
        "outputId": "79842da0-d95c-4bf1-aff3-6f4a538dd831"
      },
      "execution_count": 433,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47])"
            ]
          },
          "metadata": {},
          "execution_count": 433
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWfmguUjsqDT",
        "outputId": "0203165e-7420-440c-bbbb-e65d27bc96c5"
      },
      "execution_count": 434,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([47, 56, 57, 58,  1, 15, 47, 58, 47, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 434
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(target_data),len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUZDfrk5pit4",
        "outputId": "747d36c0-6389-4f95-f68c-965d2b354e6b"
      },
      "execution_count": 435,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 435
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(Block_size):\n",
        "    x = train_data[:t+1]\n",
        "    y = target_data[t]\n",
        "    print(f\"input is {x} and target is {y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4NwzEjFpxWg",
        "outputId": "3a0adc0a-8181-4138-f5aa-983ec2a0951b"
      },
      "execution_count": 436,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input is tensor([18]) and target is 47\n",
            "input is tensor([18, 47]) and target is 56\n",
            "input is tensor([18, 47, 56]) and target is 57\n",
            "input is tensor([18, 47, 56, 57]) and target is 58\n",
            "input is tensor([18, 47, 56, 57, 58]) and target is 1\n",
            "input is tensor([18, 47, 56, 57, 58,  1]) and target is 15\n",
            "input is tensor([18, 47, 56, 57, 58,  1, 15]) and target is 47\n",
            "input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) and target is 58\n",
            "input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58]) and target is 47\n",
            "input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47]) and target is 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4# how many independent sequences will we process in parallel?\n",
        "block_size = 8 # what is the maximum context length for predictions?"
      ],
      "metadata": {
        "id": "vGvJMluPswT5"
      },
      "execution_count": 437,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ix = torch.randint(len(dataset) - block_size, (batch_size,))"
      ],
      "metadata": {
        "id": "2Rdmpw1at17z"
      },
      "execution_count": 438,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufmy61xOuISo",
        "outputId": "79500ebd-9f0d-4017-b777-a40c500eee13"
      },
      "execution_count": 439,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1078327,  453969,   41646,  671252])"
            ]
          },
          "metadata": {},
          "execution_count": 439
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0LEO2bsRmY4",
        "outputId": "e1092404-8579-4a0b-9c54-5f519761ca88"
      },
      "execution_count": 440,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 440
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "def get_batch (split):\n",
        "\n",
        "  data = train_dataset if split == 'train' else validation_dataset\n",
        "\n",
        "  ix = torch.randint(len(data)-block_size ,(batch_size,))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix ])\n",
        "\n",
        "  y = torch.stack(tuple(data[i+1:i+block_size+1] for i in ix ))\n",
        "\n",
        "  return x,y\n",
        "\n",
        "xt ,yt = get_batch('train')\n"
      ],
      "metadata": {
        "id": "UjFjGmCzMBKh"
      },
      "execution_count": 441,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xt.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2HB-twjMBN-",
        "outputId": "e209aa24-dde4-4ad4-d4b5-3e02a7f10a03"
      },
      "execution_count": 442,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 442
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z-7qke7Smg2",
        "outputId": "2ae85218-6ae9-4bf9-b42c-20f7867c68e8"
      },
      "execution_count": 443,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[63,  8,  0,  0, 19, 24, 27, 33],\n",
              "        [59, 45, 46, 58,  1, 46, 43,  1],\n",
              "        [43, 57,  1, 53, 50, 42,  1, 46],\n",
              "        [41, 47, 43, 52, 58,  1, 56, 47]])"
            ]
          },
          "metadata": {},
          "execution_count": 443
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "1KnLfxJ_MBRD"
      },
      "execution_count": 444,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_embedding_table = nn.Embedding(65, 10)\n",
        "token_embedding_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAyFuSSsTJEo",
        "outputId": "1bd6d988-a8e9-42db-c6a8-dcb45166a544"
      },
      "execution_count": 445,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(65, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 445
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = token_embedding_table(xt)\n",
        "logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4IcuUpsUiOd",
        "outputId": "1335c6a9-f862-4cb4-9847-16529164a045"
      },
      "execution_count": 446,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.3924e+00,  1.3114e+00,  1.3805e+00,  3.5440e-01,  3.5861e-01,\n",
              "          -8.7726e-01,  3.2667e-01, -5.6669e-01, -1.6618e-01,  1.3520e+00],\n",
              "         [ 1.1708e+00, -2.6099e-01, -9.5709e-01,  6.3591e-01, -1.4204e-01,\n",
              "          -1.5207e-01,  6.5104e-02, -1.7956e+00,  1.3145e+00,  1.7042e+00],\n",
              "         [-1.5935e+00, -1.2706e+00,  6.9033e-01, -1.9614e-01,  6.1403e-03,\n",
              "          -9.6651e-01,  3.5829e-01,  1.0729e-01, -4.1896e-01, -4.3699e-01],\n",
              "         [ 6.2577e-01,  2.5510e-02,  9.5451e-01,  6.4349e-02, -5.0240e-01,\n",
              "          -2.0255e-01, -1.5671e+00, -1.0980e+00,  2.3596e-01, -2.3978e-01],\n",
              "         [ 6.2577e-01,  2.5510e-02,  9.5451e-01,  6.4349e-02, -5.0240e-01,\n",
              "          -2.0255e-01, -1.5671e+00, -1.0980e+00,  2.3596e-01, -2.3978e-01],\n",
              "         [-4.3205e-01, -1.4938e+00,  1.0785e+00, -6.1495e-01, -4.5885e-01,\n",
              "           5.6748e-01,  9.5883e-02, -1.5700e+00,  3.7396e-01, -1.4207e-01],\n",
              "         [ 4.2716e-01, -2.8192e-01, -1.2773e-02, -8.7792e-01,  1.3680e+00,\n",
              "          -7.9199e-01, -8.8244e-01,  6.3872e-01,  1.1192e+00, -1.9079e+00],\n",
              "         [-1.2685e-01, -3.4900e-01,  7.5198e-01, -6.2878e-02, -7.1113e-01,\n",
              "           9.8100e-01,  1.5095e+00, -1.5489e+00, -1.0653e+00,  1.0056e+00]],\n",
              "\n",
              "        [[ 4.1383e-01, -1.4386e+00,  1.2962e+00, -2.2434e+00,  5.2718e-01,\n",
              "          -1.5849e-01,  1.2702e+00,  1.6342e+00, -3.3823e-01, -3.8124e-01],\n",
              "         [ 6.6978e-03, -3.7117e-01, -2.0707e+00, -1.8788e+00, -8.2754e-01,\n",
              "           3.1572e-01,  7.4459e-01,  9.3237e-01, -8.1052e-01, -1.0706e-01],\n",
              "         [-1.4546e+00,  2.4102e-01,  1.6742e+00, -2.3967e-01,  3.4150e-01,\n",
              "           1.1158e-01, -1.0796e+00,  3.5018e-03,  6.8618e-04,  7.9731e-02],\n",
              "         [ 2.1229e-01, -8.9251e-01, -2.7000e-01, -1.3783e+00,  7.5047e-02,\n",
              "           6.5496e-01, -5.0057e-01, -2.1613e-01, -1.7245e-01,  6.8928e-02],\n",
              "         [-1.3924e+00,  1.3114e+00,  1.3805e+00,  3.5440e-01,  3.5861e-01,\n",
              "          -8.7726e-01,  3.2667e-01, -5.6669e-01, -1.6618e-01,  1.3520e+00],\n",
              "         [-9.2111e-01,  1.5433e+00, -3.6756e-01, -7.4827e-01, -1.0058e-01,\n",
              "           7.3073e-01, -2.0371e+00,  4.9314e-01,  1.4870e+00,  5.9103e-01],\n",
              "         [ 2.1229e-01, -8.9251e-01, -2.7000e-01, -1.3783e+00,  7.5047e-02,\n",
              "           6.5496e-01, -5.0057e-01, -2.1613e-01, -1.7245e-01,  6.8928e-02],\n",
              "         [ 5.3095e-02, -6.6554e-01, -1.1730e+00,  2.5181e+00,  1.6212e+00,\n",
              "          -1.8134e+00, -1.0200e-01,  1.2831e-01, -4.1332e-01, -1.2003e+00]],\n",
              "\n",
              "        [[-5.7443e-01,  1.2531e+00,  5.8637e-01,  9.1139e-01,  8.9507e-01,\n",
              "          -7.5235e-01,  1.6730e+00, -4.2359e-02, -1.1758e-01,  1.0546e+00],\n",
              "         [ 5.3095e-02, -6.6554e-01, -1.1730e+00,  2.5181e+00,  1.6212e+00,\n",
              "          -1.8134e+00, -1.0200e-01,  1.2831e-01, -4.1332e-01, -1.2003e+00],\n",
              "         [ 7.5347e-01, -5.3594e-01, -4.1783e-01,  1.1620e-01,  2.9924e-01,\n",
              "           8.2467e-01,  1.5877e-01, -2.3106e+00,  3.2266e-01,  1.5431e+00],\n",
              "         [-9.2111e-01,  1.5433e+00, -3.6756e-01, -7.4827e-01, -1.0058e-01,\n",
              "           7.3073e-01, -2.0371e+00,  4.9314e-01,  1.4870e+00,  5.9103e-01],\n",
              "         [-1.0159e-01, -3.0157e-01,  4.5073e-01, -1.1690e+00,  1.6037e+00,\n",
              "          -8.3240e-01, -3.3513e-01,  1.0041e+00,  8.6564e-01,  1.6879e-01],\n",
              "         [-1.0835e+00,  3.0475e-01,  6.1643e-01, -1.0682e+00,  1.7872e+00,\n",
              "           8.9457e-02, -3.7475e-01, -4.7815e-01, -4.7661e-01, -3.0513e-01],\n",
              "         [ 6.0714e-01, -1.9218e+00,  1.2453e+00,  1.0621e+00,  5.5124e-01,\n",
              "          -1.2364e+00,  9.4089e-01,  7.6084e-01, -1.7231e-01, -3.4940e-01],\n",
              "         [-9.2111e-01,  1.5433e+00, -3.6756e-01, -7.4827e-01, -1.0058e-01,\n",
              "           7.3073e-01, -2.0371e+00,  4.9314e-01,  1.4870e+00,  5.9103e-01]],\n",
              "\n",
              "        [[-1.0023e+00, -1.9870e+00, -1.2166e-01, -8.0738e-01, -8.5054e-01,\n",
              "          -3.4352e-01, -1.8207e-01, -1.4338e+00,  2.0330e+00, -5.0623e-01],\n",
              "         [ 1.7475e-01,  5.2430e-01,  7.2791e-01, -1.3588e+00, -6.9754e-01,\n",
              "           3.5226e-01,  1.0207e+00,  3.2082e+00, -3.7624e+00, -5.3301e-01],\n",
              "         [-1.0206e+00, -6.9661e-01,  1.1479e+00, -1.5735e+00,  1.3876e+00,\n",
              "           7.2512e-01, -1.2729e-01,  1.1888e+00,  5.8529e-01, -1.2204e+00],\n",
              "         [ 5.3095e-02, -6.6554e-01, -1.1730e+00,  2.5181e+00,  1.6212e+00,\n",
              "          -1.8134e+00, -1.0200e-01,  1.2831e-01, -4.1332e-01, -1.2003e+00],\n",
              "         [-1.0023e+00, -1.9870e+00, -1.2166e-01, -8.0738e-01, -8.5054e-01,\n",
              "          -3.4352e-01, -1.8207e-01, -1.4338e+00,  2.0330e+00, -5.0623e-01],\n",
              "         [-1.3924e+00,  1.3114e+00,  1.3805e+00,  3.5440e-01,  3.5861e-01,\n",
              "          -8.7726e-01,  3.2667e-01, -5.6669e-01, -1.6618e-01,  1.3520e+00],\n",
              "         [-9.2111e-01,  1.5433e+00, -3.6756e-01, -7.4827e-01, -1.0058e-01,\n",
              "           7.3073e-01, -2.0371e+00,  4.9314e-01,  1.4870e+00,  5.9103e-01],\n",
              "         [ 2.9900e-01,  1.1986e-01, -1.2433e+00,  1.7859e+00, -2.7894e-01,\n",
              "          -4.2321e-01, -6.1742e-01,  2.6432e-01, -3.5423e-01,  6.6902e-01]]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 446
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B,T,C = logits.shape\n",
        "log =logits.view(B*T,C)\n",
        "log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnahJoY7bZsd",
        "outputId": "a5f81d95-78d8-416c-e7f9-b54469dd0423"
      },
      "execution_count": 447,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.3924e+00,  1.3114e+00,  1.3805e+00,  3.5440e-01,  3.5861e-01,\n",
              "         -8.7726e-01,  3.2667e-01, -5.6669e-01, -1.6618e-01,  1.3520e+00],\n",
              "        [ 1.1708e+00, -2.6099e-01, -9.5709e-01,  6.3591e-01, -1.4204e-01,\n",
              "         -1.5207e-01,  6.5104e-02, -1.7956e+00,  1.3145e+00,  1.7042e+00],\n",
              "        [-1.5935e+00, -1.2706e+00,  6.9033e-01, -1.9614e-01,  6.1403e-03,\n",
              "         -9.6651e-01,  3.5829e-01,  1.0729e-01, -4.1896e-01, -4.3699e-01],\n",
              "        [ 6.2577e-01,  2.5510e-02,  9.5451e-01,  6.4349e-02, -5.0240e-01,\n",
              "         -2.0255e-01, -1.5671e+00, -1.0980e+00,  2.3596e-01, -2.3978e-01],\n",
              "        [ 6.2577e-01,  2.5510e-02,  9.5451e-01,  6.4349e-02, -5.0240e-01,\n",
              "         -2.0255e-01, -1.5671e+00, -1.0980e+00,  2.3596e-01, -2.3978e-01],\n",
              "        [-4.3205e-01, -1.4938e+00,  1.0785e+00, -6.1495e-01, -4.5885e-01,\n",
              "          5.6748e-01,  9.5883e-02, -1.5700e+00,  3.7396e-01, -1.4207e-01],\n",
              "        [ 4.2716e-01, -2.8192e-01, -1.2773e-02, -8.7792e-01,  1.3680e+00,\n",
              "         -7.9199e-01, -8.8244e-01,  6.3872e-01,  1.1192e+00, -1.9079e+00],\n",
              "        [-1.2685e-01, -3.4900e-01,  7.5198e-01, -6.2878e-02, -7.1113e-01,\n",
              "          9.8100e-01,  1.5095e+00, -1.5489e+00, -1.0653e+00,  1.0056e+00],\n",
              "        [ 4.1383e-01, -1.4386e+00,  1.2962e+00, -2.2434e+00,  5.2718e-01,\n",
              "         -1.5849e-01,  1.2702e+00,  1.6342e+00, -3.3823e-01, -3.8124e-01],\n",
              "        [ 6.6978e-03, -3.7117e-01, -2.0707e+00, -1.8788e+00, -8.2754e-01,\n",
              "          3.1572e-01,  7.4459e-01,  9.3237e-01, -8.1052e-01, -1.0706e-01],\n",
              "        [-1.4546e+00,  2.4102e-01,  1.6742e+00, -2.3967e-01,  3.4150e-01,\n",
              "          1.1158e-01, -1.0796e+00,  3.5018e-03,  6.8618e-04,  7.9731e-02],\n",
              "        [ 2.1229e-01, -8.9251e-01, -2.7000e-01, -1.3783e+00,  7.5047e-02,\n",
              "          6.5496e-01, -5.0057e-01, -2.1613e-01, -1.7245e-01,  6.8928e-02],\n",
              "        [-1.3924e+00,  1.3114e+00,  1.3805e+00,  3.5440e-01,  3.5861e-01,\n",
              "         -8.7726e-01,  3.2667e-01, -5.6669e-01, -1.6618e-01,  1.3520e+00],\n",
              "        [-9.2111e-01,  1.5433e+00, -3.6756e-01, -7.4827e-01, -1.0058e-01,\n",
              "          7.3073e-01, -2.0371e+00,  4.9314e-01,  1.4870e+00,  5.9103e-01],\n",
              "        [ 2.1229e-01, -8.9251e-01, -2.7000e-01, -1.3783e+00,  7.5047e-02,\n",
              "          6.5496e-01, -5.0057e-01, -2.1613e-01, -1.7245e-01,  6.8928e-02],\n",
              "        [ 5.3095e-02, -6.6554e-01, -1.1730e+00,  2.5181e+00,  1.6212e+00,\n",
              "         -1.8134e+00, -1.0200e-01,  1.2831e-01, -4.1332e-01, -1.2003e+00],\n",
              "        [-5.7443e-01,  1.2531e+00,  5.8637e-01,  9.1139e-01,  8.9507e-01,\n",
              "         -7.5235e-01,  1.6730e+00, -4.2359e-02, -1.1758e-01,  1.0546e+00],\n",
              "        [ 5.3095e-02, -6.6554e-01, -1.1730e+00,  2.5181e+00,  1.6212e+00,\n",
              "         -1.8134e+00, -1.0200e-01,  1.2831e-01, -4.1332e-01, -1.2003e+00],\n",
              "        [ 7.5347e-01, -5.3594e-01, -4.1783e-01,  1.1620e-01,  2.9924e-01,\n",
              "          8.2467e-01,  1.5877e-01, -2.3106e+00,  3.2266e-01,  1.5431e+00],\n",
              "        [-9.2111e-01,  1.5433e+00, -3.6756e-01, -7.4827e-01, -1.0058e-01,\n",
              "          7.3073e-01, -2.0371e+00,  4.9314e-01,  1.4870e+00,  5.9103e-01],\n",
              "        [-1.0159e-01, -3.0157e-01,  4.5073e-01, -1.1690e+00,  1.6037e+00,\n",
              "         -8.3240e-01, -3.3513e-01,  1.0041e+00,  8.6564e-01,  1.6879e-01],\n",
              "        [-1.0835e+00,  3.0475e-01,  6.1643e-01, -1.0682e+00,  1.7872e+00,\n",
              "          8.9457e-02, -3.7475e-01, -4.7815e-01, -4.7661e-01, -3.0513e-01],\n",
              "        [ 6.0714e-01, -1.9218e+00,  1.2453e+00,  1.0621e+00,  5.5124e-01,\n",
              "         -1.2364e+00,  9.4089e-01,  7.6084e-01, -1.7231e-01, -3.4940e-01],\n",
              "        [-9.2111e-01,  1.5433e+00, -3.6756e-01, -7.4827e-01, -1.0058e-01,\n",
              "          7.3073e-01, -2.0371e+00,  4.9314e-01,  1.4870e+00,  5.9103e-01],\n",
              "        [-1.0023e+00, -1.9870e+00, -1.2166e-01, -8.0738e-01, -8.5054e-01,\n",
              "         -3.4352e-01, -1.8207e-01, -1.4338e+00,  2.0330e+00, -5.0623e-01],\n",
              "        [ 1.7475e-01,  5.2430e-01,  7.2791e-01, -1.3588e+00, -6.9754e-01,\n",
              "          3.5226e-01,  1.0207e+00,  3.2082e+00, -3.7624e+00, -5.3301e-01],\n",
              "        [-1.0206e+00, -6.9661e-01,  1.1479e+00, -1.5735e+00,  1.3876e+00,\n",
              "          7.2512e-01, -1.2729e-01,  1.1888e+00,  5.8529e-01, -1.2204e+00],\n",
              "        [ 5.3095e-02, -6.6554e-01, -1.1730e+00,  2.5181e+00,  1.6212e+00,\n",
              "         -1.8134e+00, -1.0200e-01,  1.2831e-01, -4.1332e-01, -1.2003e+00],\n",
              "        [-1.0023e+00, -1.9870e+00, -1.2166e-01, -8.0738e-01, -8.5054e-01,\n",
              "         -3.4352e-01, -1.8207e-01, -1.4338e+00,  2.0330e+00, -5.0623e-01],\n",
              "        [-1.3924e+00,  1.3114e+00,  1.3805e+00,  3.5440e-01,  3.5861e-01,\n",
              "         -8.7726e-01,  3.2667e-01, -5.6669e-01, -1.6618e-01,  1.3520e+00],\n",
              "        [-9.2111e-01,  1.5433e+00, -3.6756e-01, -7.4827e-01, -1.0058e-01,\n",
              "          7.3073e-01, -2.0371e+00,  4.9314e-01,  1.4870e+00,  5.9103e-01],\n",
              "        [ 2.9900e-01,  1.1986e-01, -1.2433e+00,  1.7859e+00, -2.7894e-01,\n",
              "         -4.2321e-01, -6.1742e-01,  2.6432e-01, -3.5423e-01,  6.6902e-01]],\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 447
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits[:,-1,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f9YBnJclmbe",
        "outputId": "9f65cd7d-59d6-4821-8411-e36cb25923b3"
      },
      "execution_count": 448,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1269, -0.3490,  0.7520, -0.0629, -0.7111,  0.9810,  1.5095, -1.5489,\n",
              "         -1.0653,  1.0056],\n",
              "        [ 0.0531, -0.6655, -1.1730,  2.5181,  1.6212, -1.8134, -0.1020,  0.1283,\n",
              "         -0.4133, -1.2003],\n",
              "        [-0.9211,  1.5433, -0.3676, -0.7483, -0.1006,  0.7307, -2.0371,  0.4931,\n",
              "          1.4870,  0.5910],\n",
              "        [ 0.2990,  0.1199, -1.2433,  1.7859, -0.2789, -0.4232, -0.6174,  0.2643,\n",
              "         -0.3542,  0.6690]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 448
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities = F.softmax(log, dim=-1)\n",
        "probabilities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH47qjVmU7Ze",
        "outputId": "d084590e-b555-42b3-d2ea-b8147900ba48"
      },
      "execution_count": 449,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.3901e-02, 2.0763e-01, 2.2248e-01, 7.9738e-02, 8.0074e-02, 2.3268e-02,\n",
              "         7.7557e-02, 3.1742e-02, 4.7378e-02, 2.1624e-01],\n",
              "        [1.7481e-01, 4.1756e-02, 2.0817e-02, 1.0239e-01, 4.7031e-02, 4.6561e-02,\n",
              "         5.7855e-02, 9.0003e-03, 2.0181e-01, 2.9798e-01],\n",
              "        [2.3811e-02, 3.2884e-02, 2.3368e-01, 9.6303e-02, 1.1789e-01, 4.4573e-02,\n",
              "         1.6766e-01, 1.3044e-01, 7.7067e-02, 7.5689e-02],\n",
              "        [1.7678e-01, 9.6995e-02, 2.4559e-01, 1.0084e-01, 5.7211e-02, 7.7215e-02,\n",
              "         1.9729e-02, 3.1538e-02, 1.1971e-01, 7.4393e-02],\n",
              "        [1.7678e-01, 9.6995e-02, 2.4559e-01, 1.0084e-01, 5.7211e-02, 7.7215e-02,\n",
              "         1.9729e-02, 3.1538e-02, 1.1971e-01, 7.4393e-02],\n",
              "        [6.2540e-02, 2.1630e-02, 2.8326e-01, 5.2086e-02, 6.0886e-02, 1.6992e-01,\n",
              "         1.0603e-01, 2.0043e-02, 1.4002e-01, 8.3578e-02],\n",
              "        [1.1280e-01, 5.5509e-02, 7.2654e-02, 3.0587e-02, 2.8902e-01, 3.3331e-02,\n",
              "         3.0448e-02, 1.3938e-01, 2.2535e-01, 1.0920e-02],\n",
              "        [5.6394e-02, 4.5160e-02, 1.3580e-01, 6.0120e-02, 3.1440e-02, 1.7075e-01,\n",
              "         2.8966e-01, 1.3604e-02, 2.2063e-02, 1.7500e-01],\n",
              "        [8.3375e-02, 1.3078e-02, 2.0149e-01, 5.8484e-03, 9.3382e-02, 4.7041e-02,\n",
              "         1.9632e-01, 2.8252e-01, 3.9303e-02, 3.7648e-02],\n",
              "        [1.0301e-01, 7.0594e-02, 1.2903e-02, 1.5632e-02, 4.4727e-02, 1.4031e-01,\n",
              "         2.1545e-01, 2.5995e-01, 4.5495e-02, 9.1933e-02],\n",
              "        [1.7195e-02, 9.3711e-02, 3.9284e-01, 5.7947e-02, 1.0362e-01, 8.2333e-02,\n",
              "         2.5018e-02, 7.3899e-02, 7.3691e-02, 7.9753e-02],\n",
              "        [1.3755e-01, 4.5568e-02, 8.4921e-02, 2.8035e-02, 1.1991e-01, 2.1415e-01,\n",
              "         6.7434e-02, 8.9621e-02, 9.3623e-02, 1.1918e-01],\n",
              "        [1.3901e-02, 2.0763e-01, 2.2248e-01, 7.9738e-02, 8.0074e-02, 2.3268e-02,\n",
              "         7.7557e-02, 3.1742e-02, 4.7378e-02, 2.1624e-01],\n",
              "        [2.3114e-02, 2.7174e-01, 4.0205e-02, 2.7476e-02, 5.2509e-02, 1.2058e-01,\n",
              "         7.5717e-03, 9.5078e-02, 2.5687e-01, 1.0486e-01],\n",
              "        [1.3755e-01, 4.5568e-02, 8.4921e-02, 2.8035e-02, 1.1991e-01, 2.1415e-01,\n",
              "         6.7434e-02, 8.9621e-02, 9.3623e-02, 1.1918e-01],\n",
              "        [4.6853e-02, 2.2837e-02, 1.3749e-02, 5.5114e-01, 2.2477e-01, 7.2463e-03,\n",
              "         4.0122e-02, 5.0514e-02, 2.9389e-02, 1.3378e-02],\n",
              "        [2.6415e-02, 1.6426e-01, 8.4329e-02, 1.1672e-01, 1.1483e-01, 2.2110e-02,\n",
              "         2.4997e-01, 4.4970e-02, 4.1712e-02, 1.3469e-01],\n",
              "        [4.6853e-02, 2.2837e-02, 1.3749e-02, 5.5114e-01, 2.2477e-01, 7.2463e-03,\n",
              "         4.0122e-02, 5.0514e-02, 2.9389e-02, 1.3378e-02],\n",
              "        [1.3748e-01, 3.7866e-02, 4.2613e-02, 7.2689e-02, 8.7289e-02, 1.4762e-01,\n",
              "         7.5850e-02, 6.4197e-03, 8.9358e-02, 3.0282e-01],\n",
              "        [2.3114e-02, 2.7174e-01, 4.0205e-02, 2.7476e-02, 5.2509e-02, 1.2058e-01,\n",
              "         7.5717e-03, 9.5078e-02, 2.5687e-01, 1.0486e-01],\n",
              "        [5.6695e-02, 4.6419e-02, 9.8495e-02, 1.9498e-02, 3.1198e-01, 2.7300e-02,\n",
              "         4.4887e-02, 1.7129e-01, 1.4914e-01, 7.4297e-02],\n",
              "        [2.4842e-02, 9.9564e-02, 1.3598e-01, 2.5225e-02, 4.3846e-01, 8.0279e-02,\n",
              "         5.0466e-02, 4.5508e-02, 4.5579e-02, 5.4105e-02],\n",
              "        [1.1040e-01, 8.8033e-03, 2.0899e-01, 1.7400e-01, 1.0440e-01, 1.7472e-02,\n",
              "         1.5414e-01, 1.2874e-01, 5.0636e-02, 4.2418e-02],\n",
              "        [2.3114e-02, 2.7174e-01, 4.0205e-02, 2.7476e-02, 5.2509e-02, 1.2058e-01,\n",
              "         7.5717e-03, 9.5078e-02, 2.5687e-01, 1.0486e-01],\n",
              "        [2.9878e-02, 1.1162e-02, 7.2081e-02, 3.6309e-02, 3.4776e-02, 5.7739e-02,\n",
              "         6.7856e-02, 1.9407e-02, 6.2172e-01, 4.9069e-02],\n",
              "        [3.3789e-02, 4.7927e-02, 5.8750e-02, 7.2905e-03, 1.4123e-02, 4.0352e-02,\n",
              "         7.8732e-02, 7.0173e-01, 6.5900e-04, 1.6649e-02],\n",
              "        [2.1785e-02, 3.0122e-02, 1.9051e-01, 1.2532e-02, 2.4213e-01, 1.2483e-01,\n",
              "         5.3226e-02, 1.9848e-01, 1.0854e-01, 1.7841e-02],\n",
              "        [4.6853e-02, 2.2837e-02, 1.3749e-02, 5.5114e-01, 2.2477e-01, 7.2463e-03,\n",
              "         4.0122e-02, 5.0514e-02, 2.9389e-02, 1.3378e-02],\n",
              "        [2.9878e-02, 1.1162e-02, 7.2081e-02, 3.6309e-02, 3.4776e-02, 5.7739e-02,\n",
              "         6.7856e-02, 1.9407e-02, 6.2172e-01, 4.9069e-02],\n",
              "        [1.3901e-02, 2.0763e-01, 2.2248e-01, 7.9738e-02, 8.0074e-02, 2.3268e-02,\n",
              "         7.7557e-02, 3.1742e-02, 4.7378e-02, 2.1624e-01],\n",
              "        [2.3114e-02, 2.7174e-01, 4.0205e-02, 2.7476e-02, 5.2509e-02, 1.2058e-01,\n",
              "         7.5717e-03, 9.5078e-02, 2.5687e-01, 1.0486e-01],\n",
              "        [9.2133e-02, 7.7023e-02, 1.9707e-02, 4.0753e-01, 5.1692e-02, 4.4747e-02,\n",
              "         3.6848e-02, 8.8993e-02, 4.7943e-02, 1.3339e-01]],\n",
              "       grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 449
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities[-1 ,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LknhOxgRit72",
        "outputId": "c91b521c-6256-45be-d9f7-ed94430da88f"
      },
      "execution_count": 450,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0921, 0.0770, 0.0197, 0.4075, 0.0517, 0.0447, 0.0368, 0.0890, 0.0479,\n",
              "        0.1334], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 450
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log[:,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59O-XiB4dR6c",
        "outputId": "f83ac615-421c-4f27-e859-857c077d829a"
      },
      "execution_count": 451,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.3924,  1.1708, -1.5935,  0.6258,  0.6258, -0.4320,  0.4272, -0.1269,\n",
              "         0.4138,  0.0067, -1.4546,  0.2123, -1.3924, -0.9211,  0.2123,  0.0531,\n",
              "        -0.5744,  0.0531,  0.7535, -0.9211, -0.1016, -1.0835,  0.6071, -0.9211,\n",
              "        -1.0023,  0.1747, -1.0206,  0.0531, -1.0023, -1.3924, -0.9211,  0.2990],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 451
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(log[:,0]).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbxWorfYdJMP",
        "outputId": "96c3d2f1-b702-4d55-c38b-fe5986a180bd"
      },
      "execution_count": 452,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-452-3f09f1592ad6>:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  F.softmax(log[:,0]).sum()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 452
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "-ABCt4o44h5G"
      },
      "execution_count": 477,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bigrammodel(nn.Module):\n",
        "\n",
        "  def __init__(self,voc_size):\n",
        "     super().__init__()\n",
        "     self.token_embeding_tabel = nn.Embedding(voc_size,voc_size)\n",
        "\n",
        "  def forward(self,idx ,targets = None):\n",
        "      logits = self.token_embeding_tabel(idx)\n",
        "\n",
        "      if targets is None:\n",
        "        loss = None\n",
        "\n",
        "      else :\n",
        "        B,T,C =logits.shape\n",
        "        logits = logits.view(B*T,C)\n",
        "        # prediction = F.softmax(logits , dim = -1)\n",
        "        targets = targets.view(B*T)\n",
        "        loss = F.cross_entropy(logits,targets)\n",
        "\n",
        "      return logits ,loss\n",
        "\n",
        "  def generate(self,idx,max_token):\n",
        "\n",
        "    for _ in range(max_token):\n",
        "        logits ,loss  = self(idx)\n",
        "        log =  logits[:,-1,:]\n",
        "        pred = F.softmax(log , dim = -1)\n",
        "        dx_next = torch.multinomial(pred, num_samples=1)\n",
        "        idx = torch.cat((idx ,dx_next),dim = 1)\n",
        "    return idx\n"
      ],
      "metadata": {
        "id": "KmuQ8XmDa8yd"
      },
      "execution_count": 490,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = Bigrammodel(65)"
      ],
      "metadata": {
        "id": "6x6UNUApsfsH"
      },
      "execution_count": 491,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log,loss = test(xt,yt)"
      ],
      "metadata": {
        "id": "FsMEyReI0fF-"
      },
      "execution_count": 492,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBXzgdqF0sw9",
        "outputId": "ce376062-f532-4207-d9b8-e23e063577fd"
      },
      "execution_count": 493,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.7580, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 493
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder(test.generate(idx = torch.zeros((1,1), dtype = torch.long), max_token = 100)[0].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_2ko3AF14pmX",
        "outputId": "97d95ec6-96dc-4dbd-f467-0323bd05d017"
      },
      "execution_count": 504,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\njVVhmTHVjv-bT3p-EuS.HhxL!GFapfRI-iA t:.h3hSU;wGKRM BrPtLhM!,efdOKaRdsdnL!WWy,DX\\nYNEqvinL,SX.3BsV&-Ez'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 504
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TP-ZKuyF9y8V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}